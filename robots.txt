# https://www.robotstxt.org/robotstxt.html
User-agent: *
Disallow: /
# to allow crawling over all pages (currently, we are blocking all crawling):
# Disallow: 
